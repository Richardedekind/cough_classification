{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "cough_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "stqp12LC8T0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Research references:\n",
        "#1) Dry/wet cough classification: https://link.springer.com/article/10.1007/s10439-013-0741-6\n",
        "#2) Pneumonia classification: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987276\n",
        "#3) https://espace.library.uq.edu.au/data/UQ_344963/s41943203_phd_submission.pdf?Expires=1585601065&Key-Pair-Id=APKAJKNBJ4MJBJNC6NLQ&Signature=Lnpf6wT8rkozSh9av7U9nGuC7WAH6KuI2Cj3Y7G366gkGlh8D-Ie1Kc~TyBAUu~uMsVltleJcSv3p6TCm6HdFnhpyoTgLcYh6eFfvQwIUqbk1Bf4JZldgB~BDKUOwY1G0pA-HoKjvIAu3avO98SMO35upakm9OEBByd4nC9aXsjKRThd6bTpq1qIuuD9gh1l5FaM6hNRB0c2lCf4Q3adx7C3FW0NMwdWhcuF45A9f~dO3zTWWSQamoo5Otc-PHMMt96TetNcML~jy9ghgJeCPY6DJLUIwQAt03fENBluS~TjTJ17WD~n51xiRofb94fEJHoRHh0d-430LLwr7BX4IA__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1m0Zx8S9Cas",
        "colab_type": "code",
        "outputId": "6a102cfe-19f9-4fc8-c7d7-5caad6338425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj_b7qHhVAOe",
        "colab_type": "code",
        "outputId": "b0c0aaaf-8aa2-4caa-be1a-3364042fdb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=c7fa1b63313839507b441873c9ee2efe815c98cc04ad654882678db9c3033cd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3-nMncBVLHh",
        "colab_type": "code",
        "outputId": "ebc6c767-c966-4c54-ddec-caf79127a236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "!pip install pysptk"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysptk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/25/4ea0932fbf0f1db42934b85011c1c825bcf57055ecde7e511f05e9fb9197/pysptk-0.1.18.tar.gz (419kB)\n",
            "\r\u001b[K     |▉                               | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 419kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pysptk) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pysptk) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from pysptk) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->pysptk) (1.18.2)\n",
            "Building wheels for collected packages: pysptk\n",
            "  Building wheel for pysptk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysptk: filename=pysptk-0.1.18-cp36-cp36m-linux_x86_64.whl size=950218 sha256=fd17555caf9ecee7ceb0115859832e26f432e981ecbcc046d5168214a69832a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/96/d2/a163240019c59504402fab713af259026af81a99dea943404a\n",
            "Successfully built pysptk\n",
            "Installing collected packages: pysptk\n",
            "Successfully installed pysptk-0.1.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie785avw8T06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "#import pywt #wavelets\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "from pydub.utils import mediainfo\n",
        "from pydub.playback import play\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sn\n",
        "import python_speech_features as spe_feats\n",
        "import pandas as pd\n",
        "from scipy.stats import kurtosis, skew\n",
        "from scipy.signal import lfilter\n",
        "import librosa\n",
        "import pysptk\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "random.seed(1)\n",
        "#settings\n",
        "import config\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1n9GnYA8T1F",
        "colab_type": "text"
      },
      "source": [
        "## Reading recordings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3txTjKc8T1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_s=[]\n",
        "all_label=[]\n",
        "all_id=[]\n",
        "all_fs=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwUzL_hJ_xyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys  \n",
        "sys.path.insert(0, '/content/config.py') #/content/config.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VttyEwI3xhWe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdjMzqVR8T1P",
        "colab_type": "code",
        "outputId": "3965e1bc-78b9-4f79-8c07-37ca4b3a5257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "#Read wav data set\n",
        "\n",
        "if config.featExtr_skip is False:\n",
        "    print(\"Readings wavs...\")\n",
        "\n",
        "    #only list files in FOLDER_PATH directory\n",
        "    wav_files = [f for f in os.listdir(config.FOLDER_PATH) if os.path.isfile(os.path.join(config.FOLDER_PATH, f))]\n",
        "    for file_name in wav_files:\n",
        "    \n",
        "        fname_noExt = os.path.splitext(file_name)[0] #file name without extension\n",
        "    \n",
        "        #full path file name\n",
        "        full_fname = config.FOLDER_PATH+file_name\n",
        "        print(full_fname)\n",
        "    \n",
        "        # load audio\n",
        "        s = AudioSegment.from_wav(full_fname)\n",
        "        print(full_fname)\n",
        "        all_s.append(s)\n",
        "        #sampling rate:\n",
        "        info = mediainfo(full_fname)\n",
        "        fs = float(info['sample_rate'])\n",
        "        all_fs.append(fs)\n",
        "    \n",
        "        #get ID of recording\n",
        "        ID = fname_noExt.split('-')[-2] #for the current type of naming\n",
        "        #print(file_name)\n",
        "        #print(ID)\n",
        "        all_id.append(ID)\n",
        "        words = ['covid', 'suspect', 'healthy']\n",
        "        for l in words:\n",
        "            if l in fname_noExt:\n",
        "                label = l\n",
        "        #get label\n",
        "        #label = fname_noExt.split('-')[-1] #for the current type of naming #Change this for updated data \n",
        "        #print(label)\n",
        "        all_label.append(label)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Readings wavs...\n",
            "data/YT_set/edited_wavs/1585980696440_sentence_healthy_f_45_e9a9bfb1-300a-404a-9dae-60f0c798a1e4.wav\n",
            "data/YT_set/edited_wavs/1585980696440_sentence_healthy_f_45_e9a9bfb1-300a-404a-9dae-60f0c798a1e4.wav\n",
            "data/YT_set/edited_wavs/1586190780461_breath_suspect_m_29_9fa75acd-a59e-4116-b374-cc112ca9801e.wav\n",
            "data/YT_set/edited_wavs/1586190780461_breath_suspect_m_29_9fa75acd-a59e-4116-b374-cc112ca9801e.wav\n",
            "data/YT_set/edited_wavs/1586169776140_sentence_healthy_f_48_3b080916-a3a0-49b2-85a0-139b7713ae62.wav\n",
            "data/YT_set/edited_wavs/1586169776140_sentence_healthy_f_48_3b080916-a3a0-49b2-85a0-139b7713ae62.wav\n",
            "data/YT_set/edited_wavs/1586059457781_sentence_healthy_m_52_0f56abb0-968e-4824-a9a1-6c7534d97a78.wav\n",
            "data/YT_set/edited_wavs/1586059457781_sentence_healthy_m_52_0f56abb0-968e-4824-a9a1-6c7534d97a78.wav\n",
            "data/YT_set/edited_wavs/1585980696440_cough_healthy_f_45_e9a9bfb1-300a-404a-9dae-60f0c798a1e4.wav\n",
            "data/YT_set/edited_wavs/1585980696440_cough_healthy_f_45_e9a9bfb1-300a-404a-9dae-60f0c798a1e4.wav\n",
            "data/YT_set/edited_wavs/1586059147285_cough_healthy_m_16_3c325fd2-3026-4f58-9067-f8f66fcd4b12.wav\n",
            "data/YT_set/edited_wavs/1586059147285_cough_healthy_m_16_3c325fd2-3026-4f58-9067-f8f66fcd4b12.wav\n",
            "data/YT_set/edited_wavs/1586118644015_cough_healthy_m_36_2a8a3b41-afab-4add-9ad9-db7e2828130c.wav\n",
            "data/YT_set/edited_wavs/1586118644015_cough_healthy_m_36_2a8a3b41-afab-4add-9ad9-db7e2828130c.wav\n",
            "data/YT_set/edited_wavs/1586059147285_sentence_healthy_m_16_3c325fd2-3026-4f58-9067-f8f66fcd4b12.wav\n",
            "data/YT_set/edited_wavs/1586059147285_sentence_healthy_m_16_3c325fd2-3026-4f58-9067-f8f66fcd4b12.wav\n",
            "data/YT_set/edited_wavs/1586271244872_breath_healthy_f_56_83b06f04-17f4-4d84-bf5d-e84e6c4f0e8d.wav\n",
            "data/YT_set/edited_wavs/1586271244872_breath_healthy_f_56_83b06f04-17f4-4d84-bf5d-e84e6c4f0e8d.wav\n",
            "data/YT_set/edited_wavs/1586059457781_cough_healthy_m_52_0f56abb0-968e-4824-a9a1-6c7534d97a78.wav\n",
            "data/YT_set/edited_wavs/1586059457781_cough_healthy_m_52_0f56abb0-968e-4824-a9a1-6c7534d97a78.wav\n",
            "data/YT_set/edited_wavs/1586190780461_cough_suspect_m_29_9fa75acd-a59e-4116-b374-cc112ca9801e.wav\n",
            "data/YT_set/edited_wavs/1586190780461_cough_suspect_m_29_9fa75acd-a59e-4116-b374-cc112ca9801e.wav\n",
            "data/YT_set/edited_wavs/1585986163764_cough_healthy_m_29_fcde6e2d-1055-4f8d-9122-97806dbe1a78.wav\n",
            "data/YT_set/edited_wavs/1585986163764_cough_healthy_m_29_fcde6e2d-1055-4f8d-9122-97806dbe1a78.wav\n",
            "data/YT_set/edited_wavs/1585980696440_breath_healthy_f_45_e9a9bfb1-300a-404a-9dae-60f0c798a1e4.wav\n",
            "data/YT_set/edited_wavs/1585980696440_breath_healthy_f_45_e9a9bfb1-300a-404a-9dae-60f0c798a1e4.wav\n",
            "data/YT_set/edited_wavs/1586169776140_cough_healthy_f_48_3b080916-a3a0-49b2-85a0-139b7713ae62.wav\n",
            "data/YT_set/edited_wavs/1586169776140_cough_healthy_f_48_3b080916-a3a0-49b2-85a0-139b7713ae62.wav\n",
            "data/YT_set/edited_wavs/1586099949514_cough_healthy_m_38_14655d5a-3043-4ce9-a1a6-01f68aafc876.wav\n",
            "data/YT_set/edited_wavs/1586099949514_cough_healthy_m_38_14655d5a-3043-4ce9-a1a6-01f68aafc876.wav\n",
            "data/YT_set/edited_wavs/1586271244872_cough_healthy_f_56_83b06f04-17f4-4d84-bf5d-e84e6c4f0e8d.wav\n",
            "data/YT_set/edited_wavs/1586271244872_cough_healthy_f_56_83b06f04-17f4-4d84-bf5d-e84e6c4f0e8d.wav\n",
            "data/YT_set/edited_wavs/1586099949514_breath_healthy_m_38_14655d5a-3043-4ce9-a1a6-01f68aafc876.wav\n",
            "data/YT_set/edited_wavs/1586099949514_breath_healthy_m_38_14655d5a-3043-4ce9-a1a6-01f68aafc876.wav\n",
            "data/YT_set/edited_wavs/1586271152602_cough_healthy_f_44_1568e2b2-ac05-4ea3-8be1-8730bb3858e1.wav\n",
            "data/YT_set/edited_wavs/1586271152602_cough_healthy_f_44_1568e2b2-ac05-4ea3-8be1-8730bb3858e1.wav\n",
            "data/YT_set/edited_wavs/1586265690178_sentence_suspect_m_20_005c73d0-d16e-40a0-81be-6bc76bfc9c17.wav\n",
            "data/YT_set/edited_wavs/1586265690178_sentence_suspect_m_20_005c73d0-d16e-40a0-81be-6bc76bfc9c17.wav\n",
            "data/YT_set/edited_wavs/1586190780461_sentence_suspect_m_29_9fa75acd-a59e-4116-b374-cc112ca9801e.wav\n",
            "data/YT_set/edited_wavs/1586190780461_sentence_suspect_m_29_9fa75acd-a59e-4116-b374-cc112ca9801e.wav\n",
            "data/YT_set/edited_wavs/1585980866594_cough_covid_f_45_0cce8e64-24f1-4ec7-a311-203bb2648e9e.wav\n",
            "data/YT_set/edited_wavs/1585980866594_cough_covid_f_45_0cce8e64-24f1-4ec7-a311-203bb2648e9e.wav\n",
            "data/YT_set/edited_wavs/1585940317337_breath_healthy_m_34_c79c32e7-6665-4c5e-9458-d15930488263.wav\n",
            "data/YT_set/edited_wavs/1585940317337_breath_healthy_m_34_c79c32e7-6665-4c5e-9458-d15930488263.wav\n",
            "data/YT_set/edited_wavs/1586059457781_breath_healthy_m_52_0f56abb0-968e-4824-a9a1-6c7534d97a78.wav\n",
            "data/YT_set/edited_wavs/1586059457781_breath_healthy_m_52_0f56abb0-968e-4824-a9a1-6c7534d97a78.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhyVq7lwJw5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bea36916-1275-4b29-c5e3-6c3a60d55003"
      },
      "source": [
        "label"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'healthy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVSYcKO2BhR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f27c46f-ec0b-4b38-8ce6-65e2f67876ba"
      },
      "source": [
        "len(wav_files) # Total 36 files uploaded "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFAzqvQW8T1Y",
        "colab_type": "text"
      },
      "source": [
        "Listening to some of the audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBSlnhuYxOXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    np.where(np.array(all_label)=='healthy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6wIrNszxOLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    np.where(np.array(all_label)=='covid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGZPNaA38T1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    np.where(np.array(all_label)=='suspect')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw2Gy7qT8T1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    s=all_s[15]\n",
        "    s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7AMbOk78T1t",
        "colab_type": "text"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxLTUbJZxQPj",
        "colab_type": "code",
        "outputId": "683ab5c5-1cee-4617-a1a3-a644c83ddc70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "!pip install git+https://github.com/r9y9/pysptk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/r9y9/pysptk\n",
            "  Cloning https://github.com/r9y9/pysptk to /tmp/pip-req-build-6u74m302\n",
            "  Running command git clone -q https://github.com/r9y9/pysptk /tmp/pip-req-build-6u74m302\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pysptk==0.1.19+dbc194c) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pysptk==0.1.19+dbc194c) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from pysptk==0.1.19+dbc194c) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->pysptk==0.1.19+dbc194c) (1.18.2)\n",
            "Building wheels for collected packages: pysptk\n",
            "  Building wheel for pysptk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysptk: filename=pysptk-0.1.19+dbc194c-cp36-cp36m-linux_x86_64.whl size=951981 sha256=67fb69d07f780bfa92ef3ec6cf2c20020c8ef7e5dc2636e0a12aad767abfd0c0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3pwu12so/wheels/2a/28/31/a8ae9718b5bd5b21d46703b1d34d3c87f4cf4e604e2413607b\n",
            "Successfully built pysptk\n",
            "Installing collected packages: pysptk\n",
            "  Found existing installation: pysptk 0.1.18\n",
            "    Uninstalling pysptk-0.1.18:\n",
            "      Successfully uninstalled pysptk-0.1.18\n",
            "Successfully installed pysptk-0.1.19+dbc194c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pysptk"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjONKlk53kZA",
        "colab_type": "code",
        "outputId": "79161e1e-14d9-4b6a-c8e9-9bb66af635a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "np.shape(all_label)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQZvLEiaJICZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7906084d-87e0-4cab-f90b-9dfae61264fd"
      },
      "source": [
        "all_label #Fix this - should contain - healthy , covid, suspect - eventually classify suspect VS covid"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'covid',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'suspect',\n",
              " 'covid',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'suspect',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'suspect',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'healthy',\n",
              " 'suspect',\n",
              " 'suspect',\n",
              " 'covid',\n",
              " 'healthy',\n",
              " 'healthy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT0xoIPI8T1u",
        "colab_type": "code",
        "outputId": "174fd373-6d50-4589-b07a-4eb2514a7534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "import featureExtractionFunctions as featExtrLib\n",
        "import pysptk\n",
        "if config.featExtr_skip is False:\n",
        "\n",
        "    feats = featExtrLib.feature_extraction_Step(all_s,all_id,all_label)\n",
        "    \n",
        "       \n",
        "#Lenght of all_s, all_id and all_label must be the same\n",
        "       #Lenght is 36, of a ll arguments "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIivFH5V9T7m",
        "colab_type": "code",
        "outputId": "8b45475d-6c6f-415b-af81-9e7b52b9651b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feats.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3501, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK2O13YX8T11",
        "colab_type": "text"
      },
      "source": [
        "## Load  (or store) features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNWjMyke8T12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats_fname = 'feats_df.pkl'\n",
        "\n",
        "if config.featExtr_skip is False:\n",
        "    #Store feature df\n",
        "    feats.to_pickle(feats_fname)\n",
        "else:\n",
        "    #Load feature df\n",
        "    feats = pd.read_pickle(feats_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM_uxal58T19",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIayUJ108T19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats2 = featExtrLib.processingNaNvalues(feats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Q1EH3PGiBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "be7c6dfd-37ac-4ff0-aae3-44dca5d353b7"
      },
      "source": [
        "feats"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>kurt</th>\n",
              "      <th>logEnergy</th>\n",
              "      <th>zcr</th>\n",
              "      <th>F0</th>\n",
              "      <th>skewness</th>\n",
              "      <th>label</th>\n",
              "      <th>entropy</th>\n",
              "      <th>mfcc_0</th>\n",
              "      <th>mfcc_1</th>\n",
              "      <th>mfcc_2</th>\n",
              "      <th>mfcc_3</th>\n",
              "      <th>mfcc_4</th>\n",
              "      <th>mfcc_5</th>\n",
              "      <th>mfcc_6</th>\n",
              "      <th>mfcc_7</th>\n",
              "      <th>mfcc_8</th>\n",
              "      <th>mfcc_9</th>\n",
              "      <th>mfcc_10</th>\n",
              "      <th>mfcc_11</th>\n",
              "      <th>mfcc_12</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9dae</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-15.653560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>healthy</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-36.043653</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.317066e-14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.432169e-14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9dae</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-15.653560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>healthy</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-36.043653</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.317066e-14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.432169e-14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9dae</td>\n",
              "      <td>74.496203</td>\n",
              "      <td>7.013444</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.053929</td>\n",
              "      <td>healthy</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.106819</td>\n",
              "      <td>-55.298211</td>\n",
              "      <td>-28.633744</td>\n",
              "      <td>-12.482189</td>\n",
              "      <td>-1.831654e+01</td>\n",
              "      <td>-3.612546</td>\n",
              "      <td>-1.220201e+01</td>\n",
              "      <td>-1.757603</td>\n",
              "      <td>-10.025304</td>\n",
              "      <td>-2.662720</td>\n",
              "      <td>-9.402442</td>\n",
              "      <td>-3.606080</td>\n",
              "      <td>-7.927589</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9dae</td>\n",
              "      <td>124.891794</td>\n",
              "      <td>5.753564</td>\n",
              "      <td>0.005013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.357355</td>\n",
              "      <td>healthy</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.219481</td>\n",
              "      <td>-55.226196</td>\n",
              "      <td>-28.885721</td>\n",
              "      <td>-13.303920</td>\n",
              "      <td>-1.973971e+01</td>\n",
              "      <td>-5.508226</td>\n",
              "      <td>-1.425100e+01</td>\n",
              "      <td>-3.560505</td>\n",
              "      <td>-11.264630</td>\n",
              "      <td>-2.668989</td>\n",
              "      <td>-8.259321</td>\n",
              "      <td>-2.026840</td>\n",
              "      <td>-6.549228</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9dae</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>-15.653560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>healthy</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-36.043653</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.317066e-14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.432169e-14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3496</th>\n",
              "      <td>a9a1</td>\n",
              "      <td>3.806634</td>\n",
              "      <td>3.194136</td>\n",
              "      <td>0.463659</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.871429</td>\n",
              "      <td>healthy</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>13.243207</td>\n",
              "      <td>-11.635831</td>\n",
              "      <td>19.492475</td>\n",
              "      <td>-19.647588</td>\n",
              "      <td>1.643636e+01</td>\n",
              "      <td>-51.572527</td>\n",
              "      <td>-5.944072e+00</td>\n",
              "      <td>3.562196</td>\n",
              "      <td>7.357957</td>\n",
              "      <td>-4.385455</td>\n",
              "      <td>-34.615137</td>\n",
              "      <td>-32.429208</td>\n",
              "      <td>20.971276</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3497</th>\n",
              "      <td>a9a1</td>\n",
              "      <td>1.896420</td>\n",
              "      <td>2.751819</td>\n",
              "      <td>0.411028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.662177</td>\n",
              "      <td>healthy</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>12.149659</td>\n",
              "      <td>-12.676209</td>\n",
              "      <td>18.821759</td>\n",
              "      <td>-18.585478</td>\n",
              "      <td>2.509188e+01</td>\n",
              "      <td>-54.208612</td>\n",
              "      <td>-9.916315e+00</td>\n",
              "      <td>13.754496</td>\n",
              "      <td>11.717158</td>\n",
              "      <td>-6.106681</td>\n",
              "      <td>-29.804491</td>\n",
              "      <td>-11.296234</td>\n",
              "      <td>16.664628</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3498</th>\n",
              "      <td>a9a1</td>\n",
              "      <td>6.896554</td>\n",
              "      <td>2.908995</td>\n",
              "      <td>0.390977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.463840</td>\n",
              "      <td>healthy</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>12.603628</td>\n",
              "      <td>-8.418572</td>\n",
              "      <td>25.380305</td>\n",
              "      <td>-14.098784</td>\n",
              "      <td>9.767607e+00</td>\n",
              "      <td>-66.084484</td>\n",
              "      <td>-1.221492e+00</td>\n",
              "      <td>25.805327</td>\n",
              "      <td>11.584334</td>\n",
              "      <td>-10.279126</td>\n",
              "      <td>-15.505048</td>\n",
              "      <td>-27.169752</td>\n",
              "      <td>8.331873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499</th>\n",
              "      <td>a9a1</td>\n",
              "      <td>4.042405</td>\n",
              "      <td>2.503102</td>\n",
              "      <td>0.413534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.376938</td>\n",
              "      <td>healthy</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>11.609834</td>\n",
              "      <td>-12.090830</td>\n",
              "      <td>18.385291</td>\n",
              "      <td>-17.250677</td>\n",
              "      <td>1.286420e+01</td>\n",
              "      <td>-56.138200</td>\n",
              "      <td>-4.037472e+00</td>\n",
              "      <td>18.927159</td>\n",
              "      <td>12.880353</td>\n",
              "      <td>-5.300275</td>\n",
              "      <td>-13.042858</td>\n",
              "      <td>-19.407809</td>\n",
              "      <td>11.005639</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3500</th>\n",
              "      <td>a9a1</td>\n",
              "      <td>18.918387</td>\n",
              "      <td>2.086540</td>\n",
              "      <td>0.092732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.788559</td>\n",
              "      <td>healthy</td>\n",
              "      <td>2.375431</td>\n",
              "      <td>10.651801</td>\n",
              "      <td>-13.871909</td>\n",
              "      <td>15.036812</td>\n",
              "      <td>-19.116085</td>\n",
              "      <td>9.082431e+00</td>\n",
              "      <td>-34.270323</td>\n",
              "      <td>-9.436434e+00</td>\n",
              "      <td>-15.211507</td>\n",
              "      <td>18.161857</td>\n",
              "      <td>-4.972074</td>\n",
              "      <td>12.275145</td>\n",
              "      <td>12.498892</td>\n",
              "      <td>16.350062</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3501 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id        kurt  logEnergy       zcr   F0  ...    mfcc_12  F1  F2  F3  F4\n",
              "0     9dae   -3.000000 -15.653560  0.000000  0.0  ...   0.000000 NaN NaN NaN NaN\n",
              "1     9dae   -3.000000 -15.653560  0.000000  0.0  ...   0.000000 NaN NaN NaN NaN\n",
              "2     9dae   74.496203   7.013444  0.007519  0.0  ...  -7.927589 NaN NaN NaN NaN\n",
              "3     9dae  124.891794   5.753564  0.005013  0.0  ...  -6.549228 NaN NaN NaN NaN\n",
              "4     9dae   -3.000000 -15.653560  0.000000  0.0  ...   0.000000 NaN NaN NaN NaN\n",
              "...    ...         ...        ...       ...  ...  ...        ...  ..  ..  ..  ..\n",
              "3496  a9a1    3.806634   3.194136  0.463659  0.0  ...  20.971276 NaN NaN NaN NaN\n",
              "3497  a9a1    1.896420   2.751819  0.411028  0.0  ...  16.664628 NaN NaN NaN NaN\n",
              "3498  a9a1    6.896554   2.908995  0.390977  0.0  ...   8.331873 NaN NaN NaN NaN\n",
              "3499  a9a1    4.042405   2.503102  0.413534  0.0  ...  11.005639 NaN NaN NaN NaN\n",
              "3500  a9a1   18.918387   2.086540  0.092732  0.0  ...  16.350062 NaN NaN NaN NaN\n",
              "\n",
              "[3501 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk4bLREC8T2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = featExtrLib.createLabelDict_addLabel2df(feats2)\n",
        "mean_std_feats = featExtrLib.frame_mean_std_chunk_modeling (feats2,label_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiCuV5WMo3go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1bd344d-c5d0-4f79-8d4d-8398a95057d4"
      },
      "source": [
        "mean_std_feats.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(355, 49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBENHFc-8T2K",
        "colab_type": "text"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vUsIhkC8T2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = mean_std_feats.drop(['label','Id','subIdx'], 1).copy()\n",
        "y_train =  mean_std_feats['label'].copy()\n",
        "\n",
        "ID_train = mean_std_feats['Id']\n",
        "\n",
        "#ID_train.size --- Check the y_train labels "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5PY-NuVemmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57e810bd-43d3-4167-dd6f-f4fb4f8a83dc"
      },
      "source": [
        "y_train.unique()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['suspect', 'healthy', 'covid'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tef6_iIJeEOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "5b83a36b-b391-4507-b1fc-3c836ab651d7"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kurt_m</th>\n",
              "      <th>logEnergy_m</th>\n",
              "      <th>zcr_m</th>\n",
              "      <th>F0_m</th>\n",
              "      <th>skewness_m</th>\n",
              "      <th>entropy_m</th>\n",
              "      <th>mfcc_0_m</th>\n",
              "      <th>mfcc_1_m</th>\n",
              "      <th>mfcc_2_m</th>\n",
              "      <th>mfcc_3_m</th>\n",
              "      <th>mfcc_4_m</th>\n",
              "      <th>mfcc_5_m</th>\n",
              "      <th>mfcc_6_m</th>\n",
              "      <th>mfcc_7_m</th>\n",
              "      <th>mfcc_8_m</th>\n",
              "      <th>mfcc_9_m</th>\n",
              "      <th>mfcc_10_m</th>\n",
              "      <th>mfcc_11_m</th>\n",
              "      <th>mfcc_12_m</th>\n",
              "      <th>F1_m</th>\n",
              "      <th>F2_m</th>\n",
              "      <th>F3_m</th>\n",
              "      <th>F4_m</th>\n",
              "      <th>kurt_std</th>\n",
              "      <th>logEnergy_std</th>\n",
              "      <th>zcr_std</th>\n",
              "      <th>F0_std</th>\n",
              "      <th>skewness_std</th>\n",
              "      <th>entropy_std</th>\n",
              "      <th>mfcc_0_std</th>\n",
              "      <th>mfcc_1_std</th>\n",
              "      <th>mfcc_2_std</th>\n",
              "      <th>mfcc_3_std</th>\n",
              "      <th>mfcc_4_std</th>\n",
              "      <th>mfcc_5_std</th>\n",
              "      <th>mfcc_6_std</th>\n",
              "      <th>mfcc_7_std</th>\n",
              "      <th>mfcc_8_std</th>\n",
              "      <th>mfcc_9_std</th>\n",
              "      <th>mfcc_10_std</th>\n",
              "      <th>mfcc_11_std</th>\n",
              "      <th>mfcc_12_std</th>\n",
              "      <th>F1_std</th>\n",
              "      <th>F2_std</th>\n",
              "      <th>F3_std</th>\n",
              "      <th>F4_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.487398</td>\n",
              "      <td>3.254538</td>\n",
              "      <td>0.415539</td>\n",
              "      <td>24.143263</td>\n",
              "      <td>0.276044</td>\n",
              "      <td>8.633343</td>\n",
              "      <td>13.316072</td>\n",
              "      <td>-23.210690</td>\n",
              "      <td>12.268731</td>\n",
              "      <td>-3.097449</td>\n",
              "      <td>30.147028</td>\n",
              "      <td>1.061579</td>\n",
              "      <td>12.795347</td>\n",
              "      <td>-7.932694</td>\n",
              "      <td>3.361835</td>\n",
              "      <td>-19.220120</td>\n",
              "      <td>-10.021341</td>\n",
              "      <td>-16.532146</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>7.107979</td>\n",
              "      <td>1.378085</td>\n",
              "      <td>0.052270</td>\n",
              "      <td>30.033659</td>\n",
              "      <td>0.952407</td>\n",
              "      <td>2.991081e-02</td>\n",
              "      <td>3.232670</td>\n",
              "      <td>8.054590</td>\n",
              "      <td>16.344912</td>\n",
              "      <td>22.460246</td>\n",
              "      <td>13.796380</td>\n",
              "      <td>8.644877</td>\n",
              "      <td>7.764616</td>\n",
              "      <td>13.024584</td>\n",
              "      <td>8.941866</td>\n",
              "      <td>19.164721</td>\n",
              "      <td>18.367054</td>\n",
              "      <td>10.581726</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.778342</td>\n",
              "      <td>2.756529</td>\n",
              "      <td>0.441604</td>\n",
              "      <td>16.441803</td>\n",
              "      <td>0.341112</td>\n",
              "      <td>8.633888</td>\n",
              "      <td>12.261544</td>\n",
              "      <td>-23.963859</td>\n",
              "      <td>-0.228988</td>\n",
              "      <td>-27.514992</td>\n",
              "      <td>24.579247</td>\n",
              "      <td>1.770780</td>\n",
              "      <td>12.111861</td>\n",
              "      <td>-4.388509</td>\n",
              "      <td>1.933917</td>\n",
              "      <td>-38.021059</td>\n",
              "      <td>-21.664652</td>\n",
              "      <td>1.343692</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>3.611644</td>\n",
              "      <td>1.622843</td>\n",
              "      <td>0.028747</td>\n",
              "      <td>25.119133</td>\n",
              "      <td>0.546734</td>\n",
              "      <td>1.376022e-02</td>\n",
              "      <td>3.753590</td>\n",
              "      <td>5.061426</td>\n",
              "      <td>3.950364</td>\n",
              "      <td>14.544363</td>\n",
              "      <td>13.684918</td>\n",
              "      <td>4.883532</td>\n",
              "      <td>5.381695</td>\n",
              "      <td>10.379499</td>\n",
              "      <td>8.670674</td>\n",
              "      <td>10.651749</td>\n",
              "      <td>9.374612</td>\n",
              "      <td>10.106491</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.272703</td>\n",
              "      <td>2.009377</td>\n",
              "      <td>0.460902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078827</td>\n",
              "      <td>8.599825</td>\n",
              "      <td>10.554367</td>\n",
              "      <td>-30.706988</td>\n",
              "      <td>6.052967</td>\n",
              "      <td>-11.502601</td>\n",
              "      <td>-19.644089</td>\n",
              "      <td>-33.873367</td>\n",
              "      <td>-9.583506</td>\n",
              "      <td>-2.749914</td>\n",
              "      <td>19.409714</td>\n",
              "      <td>-8.591413</td>\n",
              "      <td>-0.251231</td>\n",
              "      <td>-2.851915</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>3.413768</td>\n",
              "      <td>1.355535</td>\n",
              "      <td>0.025887</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406483</td>\n",
              "      <td>5.264148e-02</td>\n",
              "      <td>3.137090</td>\n",
              "      <td>3.520608</td>\n",
              "      <td>8.729559</td>\n",
              "      <td>6.456737</td>\n",
              "      <td>16.094107</td>\n",
              "      <td>29.714220</td>\n",
              "      <td>16.027137</td>\n",
              "      <td>11.172731</td>\n",
              "      <td>16.365669</td>\n",
              "      <td>11.355352</td>\n",
              "      <td>10.678119</td>\n",
              "      <td>5.884397</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.138859</td>\n",
              "      <td>5.341791</td>\n",
              "      <td>0.455639</td>\n",
              "      <td>56.297680</td>\n",
              "      <td>0.093539</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>18.228545</td>\n",
              "      <td>-21.824235</td>\n",
              "      <td>-3.883372</td>\n",
              "      <td>-49.840205</td>\n",
              "      <td>57.018893</td>\n",
              "      <td>27.567263</td>\n",
              "      <td>9.696413</td>\n",
              "      <td>-37.611497</td>\n",
              "      <td>25.752038</td>\n",
              "      <td>-42.649478</td>\n",
              "      <td>-34.146931</td>\n",
              "      <td>14.131742</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>9.131717</td>\n",
              "      <td>0.635569</td>\n",
              "      <td>0.024423</td>\n",
              "      <td>28.261805</td>\n",
              "      <td>0.575494</td>\n",
              "      <td>1.776357e-15</td>\n",
              "      <td>1.498783</td>\n",
              "      <td>9.157223</td>\n",
              "      <td>7.049637</td>\n",
              "      <td>16.663458</td>\n",
              "      <td>7.913468</td>\n",
              "      <td>18.314958</td>\n",
              "      <td>4.969307</td>\n",
              "      <td>17.873812</td>\n",
              "      <td>20.135266</td>\n",
              "      <td>15.117692</td>\n",
              "      <td>12.740643</td>\n",
              "      <td>9.518290</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.013277</td>\n",
              "      <td>2.533600</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.076047</td>\n",
              "      <td>8.629439</td>\n",
              "      <td>11.788646</td>\n",
              "      <td>-36.313286</td>\n",
              "      <td>-12.760575</td>\n",
              "      <td>-30.383180</td>\n",
              "      <td>11.881278</td>\n",
              "      <td>-1.426010</td>\n",
              "      <td>3.807452</td>\n",
              "      <td>-10.524707</td>\n",
              "      <td>5.859927</td>\n",
              "      <td>-23.079763</td>\n",
              "      <td>-12.491269</td>\n",
              "      <td>2.837330</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>2.044090</td>\n",
              "      <td>0.890428</td>\n",
              "      <td>0.027614</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237062</td>\n",
              "      <td>1.938428e-02</td>\n",
              "      <td>2.050983</td>\n",
              "      <td>6.318859</td>\n",
              "      <td>4.887413</td>\n",
              "      <td>9.001948</td>\n",
              "      <td>28.238184</td>\n",
              "      <td>27.656061</td>\n",
              "      <td>12.539863</td>\n",
              "      <td>13.134631</td>\n",
              "      <td>23.081270</td>\n",
              "      <td>12.955017</td>\n",
              "      <td>9.619913</td>\n",
              "      <td>11.177006</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>11.921577</td>\n",
              "      <td>2.617082</td>\n",
              "      <td>0.422807</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.097656</td>\n",
              "      <td>7.745097</td>\n",
              "      <td>11.979889</td>\n",
              "      <td>-35.637835</td>\n",
              "      <td>-12.396089</td>\n",
              "      <td>-23.329157</td>\n",
              "      <td>-5.618912</td>\n",
              "      <td>-24.009019</td>\n",
              "      <td>-11.429958</td>\n",
              "      <td>-8.653911</td>\n",
              "      <td>-13.644327</td>\n",
              "      <td>-2.376830</td>\n",
              "      <td>-9.348086</td>\n",
              "      <td>-6.784202</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>10.234004</td>\n",
              "      <td>2.068076</td>\n",
              "      <td>0.094723</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.795525</td>\n",
              "      <td>1.598664e+00</td>\n",
              "      <td>4.754235</td>\n",
              "      <td>7.618878</td>\n",
              "      <td>3.670433</td>\n",
              "      <td>13.263026</td>\n",
              "      <td>12.346275</td>\n",
              "      <td>9.793712</td>\n",
              "      <td>5.641880</td>\n",
              "      <td>7.715234</td>\n",
              "      <td>9.470948</td>\n",
              "      <td>6.940885</td>\n",
              "      <td>11.442204</td>\n",
              "      <td>13.338935</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>5.683850</td>\n",
              "      <td>3.031414</td>\n",
              "      <td>0.430326</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.108533</td>\n",
              "      <td>8.584561</td>\n",
              "      <td>12.893581</td>\n",
              "      <td>-29.518548</td>\n",
              "      <td>9.673216</td>\n",
              "      <td>-2.808057</td>\n",
              "      <td>-15.152383</td>\n",
              "      <td>4.970744</td>\n",
              "      <td>-11.303872</td>\n",
              "      <td>-40.637660</td>\n",
              "      <td>20.856397</td>\n",
              "      <td>-14.108397</td>\n",
              "      <td>11.416597</td>\n",
              "      <td>-0.283455</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>1.342879</td>\n",
              "      <td>1.411308</td>\n",
              "      <td>0.031920</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.509826</td>\n",
              "      <td>1.164686e-01</td>\n",
              "      <td>3.236675</td>\n",
              "      <td>8.207434</td>\n",
              "      <td>13.450919</td>\n",
              "      <td>11.917909</td>\n",
              "      <td>7.435705</td>\n",
              "      <td>10.285392</td>\n",
              "      <td>15.423768</td>\n",
              "      <td>26.137803</td>\n",
              "      <td>19.249713</td>\n",
              "      <td>9.016201</td>\n",
              "      <td>7.068626</td>\n",
              "      <td>8.996079</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>5.503384</td>\n",
              "      <td>2.011310</td>\n",
              "      <td>0.436591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178825</td>\n",
              "      <td>8.422963</td>\n",
              "      <td>10.561135</td>\n",
              "      <td>-37.505530</td>\n",
              "      <td>-5.705017</td>\n",
              "      <td>-12.544108</td>\n",
              "      <td>-18.047612</td>\n",
              "      <td>-4.276282</td>\n",
              "      <td>0.332355</td>\n",
              "      <td>-11.281375</td>\n",
              "      <td>13.027097</td>\n",
              "      <td>-12.810990</td>\n",
              "      <td>-0.018912</td>\n",
              "      <td>-15.864451</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>1.074038</td>\n",
              "      <td>0.982837</td>\n",
              "      <td>0.044039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500858</td>\n",
              "      <td>5.623616e-01</td>\n",
              "      <td>2.217026</td>\n",
              "      <td>7.617375</td>\n",
              "      <td>20.022476</td>\n",
              "      <td>24.837219</td>\n",
              "      <td>15.282979</td>\n",
              "      <td>9.287309</td>\n",
              "      <td>6.227953</td>\n",
              "      <td>13.128940</td>\n",
              "      <td>17.797625</td>\n",
              "      <td>11.811849</td>\n",
              "      <td>18.531507</td>\n",
              "      <td>11.139822</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>2.848140</td>\n",
              "      <td>5.257087</td>\n",
              "      <td>0.429574</td>\n",
              "      <td>95.357857</td>\n",
              "      <td>-0.041301</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>17.984012</td>\n",
              "      <td>-14.638249</td>\n",
              "      <td>33.258152</td>\n",
              "      <td>-1.678320</td>\n",
              "      <td>12.992081</td>\n",
              "      <td>-1.862723</td>\n",
              "      <td>-23.501156</td>\n",
              "      <td>-71.666480</td>\n",
              "      <td>46.931413</td>\n",
              "      <td>-10.265955</td>\n",
              "      <td>12.537933</td>\n",
              "      <td>-20.031008</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>1.019737</td>\n",
              "      <td>0.126359</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>3.508698</td>\n",
              "      <td>0.305190</td>\n",
              "      <td>1.776357e-15</td>\n",
              "      <td>0.294434</td>\n",
              "      <td>1.686673</td>\n",
              "      <td>3.427470</td>\n",
              "      <td>9.653605</td>\n",
              "      <td>10.097659</td>\n",
              "      <td>5.645688</td>\n",
              "      <td>7.278856</td>\n",
              "      <td>7.707348</td>\n",
              "      <td>7.020424</td>\n",
              "      <td>11.734898</td>\n",
              "      <td>10.182956</td>\n",
              "      <td>5.877306</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>6.049495</td>\n",
              "      <td>4.422018</td>\n",
              "      <td>0.397995</td>\n",
              "      <td>73.825417</td>\n",
              "      <td>-0.306061</td>\n",
              "      <td>8.592324</td>\n",
              "      <td>16.064863</td>\n",
              "      <td>-18.279023</td>\n",
              "      <td>23.902942</td>\n",
              "      <td>-2.479131</td>\n",
              "      <td>6.397297</td>\n",
              "      <td>-13.070048</td>\n",
              "      <td>-15.951344</td>\n",
              "      <td>-43.922407</td>\n",
              "      <td>33.254281</td>\n",
              "      <td>-10.803560</td>\n",
              "      <td>11.671482</td>\n",
              "      <td>-7.748786</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>2.863041</td>\n",
              "      <td>0.642420</td>\n",
              "      <td>0.043014</td>\n",
              "      <td>36.972980</td>\n",
              "      <td>0.279739</td>\n",
              "      <td>1.545980e-01</td>\n",
              "      <td>1.488699</td>\n",
              "      <td>5.747723</td>\n",
              "      <td>16.293518</td>\n",
              "      <td>17.075112</td>\n",
              "      <td>7.749561</td>\n",
              "      <td>10.101882</td>\n",
              "      <td>15.055591</td>\n",
              "      <td>22.047078</td>\n",
              "      <td>21.258001</td>\n",
              "      <td>8.359991</td>\n",
              "      <td>14.422955</td>\n",
              "      <td>8.579866</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>355 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        kurt_m  logEnergy_m     zcr_m  ...     F2_std     F3_std     F4_std\n",
              "0     7.487398     3.254538  0.415539  ...   9.906564   9.906564   9.906564\n",
              "1     7.778342     2.756529  0.441604  ...  11.631959  11.631959  11.631959\n",
              "2     8.272703     2.009377  0.460902  ...   9.491288   9.491288   9.491288\n",
              "3    16.138859     5.341791  0.455639  ...   5.606985   5.606985   5.606985\n",
              "4     6.013277     2.533600  0.473684  ...   7.884767   7.884767   7.884767\n",
              "..         ...          ...       ...  ...        ...        ...        ...\n",
              "350  11.921577     2.617082  0.422807  ...  12.845447  12.845447  12.845447\n",
              "351   5.683850     3.031414  0.430326  ...   3.526151   3.526151   3.526151\n",
              "352   5.503384     2.011310  0.436591  ...  14.294878  14.294878  14.294878\n",
              "353   2.848140     5.257087  0.429574  ...   8.576278   8.576278   8.576278\n",
              "354   6.049495     4.422018  0.397995  ...   6.880705   6.880705   6.880705\n",
              "\n",
              "[355 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKviSIj8mCR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "721de8f8-1c13-4dff-9c76-cbac7ea07e1e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(355, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Af35SDHmF6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12f2e560-5d07-4ff1-eb0a-6f9398440b7a"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(355,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-WCZejj8T2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import modelTrainingFunctions as modelTrainLib\n",
        "\n",
        "pred_probs = modelTrainLib.modelTraining(X_train,y_train,ID_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn7qUu4F73SR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6dc084e9-f91b-4760-fe94-05fc2c57dbba"
      },
      "source": [
        "pred_probs"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>covid</th>\n",
              "      <th>healthy</th>\n",
              "      <th>suspect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81be</td>\n",
              "      <td>1.123231e-94</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81be</td>\n",
              "      <td>2.201075e-68</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>81be</td>\n",
              "      <td>2.098878e-79</td>\n",
              "      <td>3.535806e-17</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>81be</td>\n",
              "      <td>1.752598e-37</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>81be</td>\n",
              "      <td>9.671385e-34</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>bf5d</td>\n",
              "      <td>2.552522e-80</td>\n",
              "      <td>9.999915e-01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>bf5d</td>\n",
              "      <td>7.066177e-84</td>\n",
              "      <td>9.944494e-01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>bf5d</td>\n",
              "      <td>3.158577e-73</td>\n",
              "      <td>5.208731e-61</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>bf5d</td>\n",
              "      <td>1.081590e-43</td>\n",
              "      <td>2.701797e-01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>bf5d</td>\n",
              "      <td>5.101881e-86</td>\n",
              "      <td>1.597660e-35</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>355 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID         covid       healthy  suspect\n",
              "0    81be  1.123231e-94  1.000000e+00      NaN\n",
              "1    81be  2.201075e-68  1.000000e+00      NaN\n",
              "2    81be  2.098878e-79  3.535806e-17      NaN\n",
              "3    81be  1.752598e-37  1.000000e+00      NaN\n",
              "4    81be  9.671385e-34  1.000000e+00      NaN\n",
              "..    ...           ...           ...      ...\n",
              "350  bf5d  2.552522e-80  9.999915e-01      NaN\n",
              "351  bf5d  7.066177e-84  9.944494e-01      NaN\n",
              "352  bf5d  3.158577e-73  5.208731e-61      NaN\n",
              "353  bf5d  1.081590e-43  2.701797e-01      NaN\n",
              "354  bf5d  5.101881e-86  1.597660e-35      NaN\n",
              "\n",
              "[355 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6HOrLmp8T2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_pred_probs = modelTrainLib.get_predClass_per_audio(pred_probs, label_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Change here "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H_f9Rzt8T2c",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igPnYto-8T2d",
        "colab_type": "code",
        "outputId": "372e7c28-a69d-4b97-d6bb-eb2fcbce28a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import classifEvaluationFunctions as evalLib\n",
        "evalLib.evaluation_Step(mean_pred_probs)\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores:\n",
            "Accuracy: 0.750000\n",
            "Precision: 0.250000\n",
            "F1-score: 0.285714\n",
            "Recall: 0.333333\n",
            "\n",
            "Confusion matrix\n",
            "pred_class  healthy  All\n",
            "label                   \n",
            "covid             1    1\n",
            "healthy           9    9\n",
            "suspect           2    2\n",
            "All              12   12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XasVuLieOYfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "57be1658-c596-485c-974a-e917d5367d1e"
      },
      "source": [
        "#Test data set\n",
        "\n",
        "mean_pred_probs"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>covid</th>\n",
              "      <th>healthy</th>\n",
              "      <th>suspect</th>\n",
              "      <th>pred_class</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81be</td>\n",
              "      <td>1.851852e-02</td>\n",
              "      <td>0.738771</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>suspect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85a0</td>\n",
              "      <td>3.521368e-30</td>\n",
              "      <td>0.707561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9067</td>\n",
              "      <td>3.921928e-02</td>\n",
              "      <td>0.667245</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9122</td>\n",
              "      <td>1.014487e-17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9458</td>\n",
              "      <td>3.404701e-15</td>\n",
              "      <td>0.577781</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9ad9</td>\n",
              "      <td>7.903403e-41</td>\n",
              "      <td>0.709452</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9dae</td>\n",
              "      <td>2.307692e-01</td>\n",
              "      <td>0.762368</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a1a6</td>\n",
              "      <td>1.559700e-24</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a311</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.470925e-08</td>\n",
              "      <td>healthy</td>\n",
              "      <td>covid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a9a1</td>\n",
              "      <td>1.787282e-21</td>\n",
              "      <td>0.545619</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>b374</td>\n",
              "      <td>6.250000e-02</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>suspect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bf5d</td>\n",
              "      <td>9.013249e-45</td>\n",
              "      <td>0.730324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>healthy</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID         covid   healthy       suspect pred_class    label\n",
              "0   81be  1.851852e-02  0.738771           NaN    healthy  suspect\n",
              "1   85a0  3.521368e-30  0.707561           NaN    healthy  healthy\n",
              "2   9067  3.921928e-02  0.667245           NaN    healthy  healthy\n",
              "3   9122  1.014487e-17  1.000000           NaN    healthy  healthy\n",
              "4   9458  3.404701e-15  0.577781           NaN    healthy  healthy\n",
              "5   9ad9  7.903403e-41  0.709452           NaN    healthy  healthy\n",
              "6   9dae  2.307692e-01  0.762368           NaN    healthy  healthy\n",
              "7   a1a6  1.559700e-24  0.969697           NaN    healthy  healthy\n",
              "8   a311           NaN  1.000000  9.470925e-08    healthy    covid\n",
              "9   a9a1  1.787282e-21  0.545619           NaN    healthy  healthy\n",
              "10  b374  6.250000e-02  0.812500           NaN    healthy  suspect\n",
              "11  bf5d  9.013249e-45  0.730324           NaN    healthy  healthy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZjPagbOt8dI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "029ca5f9-8584-4ad6-d138-8016c26a33af"
      },
      "source": [
        "# y_test.shape - (36,)\n",
        "#X_test.shape - (36, 2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfK4BitVr5md",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e575b0b1-4cb0-4905-e46d-84c3b3899423"
      },
      "source": [
        "#X_train.shape -(465, 46) \n",
        "#y_train.shape -(465,)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(465,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k91F3k54_7Go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "10dd97af-8957-4660-f1e7-b371e13155bf"
      },
      "source": [
        "X_train # 46 columns , X_test also should be with 46 columns"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kurt_m</th>\n",
              "      <th>logEnergy_m</th>\n",
              "      <th>zcr_m</th>\n",
              "      <th>F0_m</th>\n",
              "      <th>skewness_m</th>\n",
              "      <th>entropy_m</th>\n",
              "      <th>mfcc_0_m</th>\n",
              "      <th>mfcc_1_m</th>\n",
              "      <th>mfcc_2_m</th>\n",
              "      <th>mfcc_3_m</th>\n",
              "      <th>mfcc_4_m</th>\n",
              "      <th>mfcc_5_m</th>\n",
              "      <th>mfcc_6_m</th>\n",
              "      <th>mfcc_7_m</th>\n",
              "      <th>mfcc_8_m</th>\n",
              "      <th>mfcc_9_m</th>\n",
              "      <th>mfcc_10_m</th>\n",
              "      <th>mfcc_11_m</th>\n",
              "      <th>mfcc_12_m</th>\n",
              "      <th>F1_m</th>\n",
              "      <th>F2_m</th>\n",
              "      <th>F3_m</th>\n",
              "      <th>F4_m</th>\n",
              "      <th>kurt_std</th>\n",
              "      <th>logEnergy_std</th>\n",
              "      <th>zcr_std</th>\n",
              "      <th>F0_std</th>\n",
              "      <th>skewness_std</th>\n",
              "      <th>entropy_std</th>\n",
              "      <th>mfcc_0_std</th>\n",
              "      <th>mfcc_1_std</th>\n",
              "      <th>mfcc_2_std</th>\n",
              "      <th>mfcc_3_std</th>\n",
              "      <th>mfcc_4_std</th>\n",
              "      <th>mfcc_5_std</th>\n",
              "      <th>mfcc_6_std</th>\n",
              "      <th>mfcc_7_std</th>\n",
              "      <th>mfcc_8_std</th>\n",
              "      <th>mfcc_9_std</th>\n",
              "      <th>mfcc_10_std</th>\n",
              "      <th>mfcc_11_std</th>\n",
              "      <th>mfcc_12_std</th>\n",
              "      <th>F1_std</th>\n",
              "      <th>F2_std</th>\n",
              "      <th>F3_std</th>\n",
              "      <th>F4_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.487398</td>\n",
              "      <td>3.254538</td>\n",
              "      <td>0.415539</td>\n",
              "      <td>24.143263</td>\n",
              "      <td>0.276044</td>\n",
              "      <td>8.633343</td>\n",
              "      <td>13.316072</td>\n",
              "      <td>-23.210690</td>\n",
              "      <td>12.268731</td>\n",
              "      <td>-3.097449</td>\n",
              "      <td>30.147028</td>\n",
              "      <td>1.061579</td>\n",
              "      <td>12.795347</td>\n",
              "      <td>-7.932694</td>\n",
              "      <td>3.361835</td>\n",
              "      <td>-19.220120</td>\n",
              "      <td>-10.021341</td>\n",
              "      <td>-16.532146</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>0.342396</td>\n",
              "      <td>7.107979</td>\n",
              "      <td>1.378085</td>\n",
              "      <td>0.052270</td>\n",
              "      <td>30.033659</td>\n",
              "      <td>0.952407</td>\n",
              "      <td>2.991081e-02</td>\n",
              "      <td>3.232670</td>\n",
              "      <td>8.054590</td>\n",
              "      <td>16.344912</td>\n",
              "      <td>22.460246</td>\n",
              "      <td>13.796380</td>\n",
              "      <td>8.644877</td>\n",
              "      <td>7.764616</td>\n",
              "      <td>13.024584</td>\n",
              "      <td>8.941866</td>\n",
              "      <td>19.164721</td>\n",
              "      <td>18.367054</td>\n",
              "      <td>10.581726</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "      <td>9.906564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.778342</td>\n",
              "      <td>2.756529</td>\n",
              "      <td>0.441604</td>\n",
              "      <td>16.441803</td>\n",
              "      <td>0.341112</td>\n",
              "      <td>8.633888</td>\n",
              "      <td>12.261544</td>\n",
              "      <td>-23.963859</td>\n",
              "      <td>-0.228988</td>\n",
              "      <td>-27.514992</td>\n",
              "      <td>24.579247</td>\n",
              "      <td>1.770780</td>\n",
              "      <td>12.111861</td>\n",
              "      <td>-4.388509</td>\n",
              "      <td>1.933917</td>\n",
              "      <td>-38.021059</td>\n",
              "      <td>-21.664652</td>\n",
              "      <td>1.343692</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>-12.415550</td>\n",
              "      <td>3.611644</td>\n",
              "      <td>1.622843</td>\n",
              "      <td>0.028747</td>\n",
              "      <td>25.119133</td>\n",
              "      <td>0.546734</td>\n",
              "      <td>1.376022e-02</td>\n",
              "      <td>3.753590</td>\n",
              "      <td>5.061426</td>\n",
              "      <td>3.950364</td>\n",
              "      <td>14.544363</td>\n",
              "      <td>13.684918</td>\n",
              "      <td>4.883532</td>\n",
              "      <td>5.381695</td>\n",
              "      <td>10.379499</td>\n",
              "      <td>8.670674</td>\n",
              "      <td>10.651749</td>\n",
              "      <td>9.374612</td>\n",
              "      <td>10.106491</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "      <td>11.631959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.272703</td>\n",
              "      <td>2.009377</td>\n",
              "      <td>0.460902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078827</td>\n",
              "      <td>8.599825</td>\n",
              "      <td>10.554367</td>\n",
              "      <td>-30.706988</td>\n",
              "      <td>6.052967</td>\n",
              "      <td>-11.502601</td>\n",
              "      <td>-19.644089</td>\n",
              "      <td>-33.873367</td>\n",
              "      <td>-9.583506</td>\n",
              "      <td>-2.749914</td>\n",
              "      <td>19.409714</td>\n",
              "      <td>-8.591413</td>\n",
              "      <td>-0.251231</td>\n",
              "      <td>-2.851915</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>5.054101</td>\n",
              "      <td>3.413768</td>\n",
              "      <td>1.355535</td>\n",
              "      <td>0.025887</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406483</td>\n",
              "      <td>5.264148e-02</td>\n",
              "      <td>3.137090</td>\n",
              "      <td>3.520608</td>\n",
              "      <td>8.729559</td>\n",
              "      <td>6.456737</td>\n",
              "      <td>16.094107</td>\n",
              "      <td>29.714220</td>\n",
              "      <td>16.027137</td>\n",
              "      <td>11.172731</td>\n",
              "      <td>16.365669</td>\n",
              "      <td>11.355352</td>\n",
              "      <td>10.678119</td>\n",
              "      <td>5.884397</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "      <td>9.491288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.138859</td>\n",
              "      <td>5.341791</td>\n",
              "      <td>0.455639</td>\n",
              "      <td>56.297680</td>\n",
              "      <td>0.093539</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>18.228545</td>\n",
              "      <td>-21.824235</td>\n",
              "      <td>-3.883372</td>\n",
              "      <td>-49.840205</td>\n",
              "      <td>57.018893</td>\n",
              "      <td>27.567263</td>\n",
              "      <td>9.696413</td>\n",
              "      <td>-37.611497</td>\n",
              "      <td>25.752038</td>\n",
              "      <td>-42.649478</td>\n",
              "      <td>-34.146931</td>\n",
              "      <td>14.131742</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>-28.225636</td>\n",
              "      <td>9.131717</td>\n",
              "      <td>0.635569</td>\n",
              "      <td>0.024423</td>\n",
              "      <td>28.261805</td>\n",
              "      <td>0.575494</td>\n",
              "      <td>1.776357e-15</td>\n",
              "      <td>1.498783</td>\n",
              "      <td>9.157223</td>\n",
              "      <td>7.049637</td>\n",
              "      <td>16.663458</td>\n",
              "      <td>7.913468</td>\n",
              "      <td>18.314958</td>\n",
              "      <td>4.969307</td>\n",
              "      <td>17.873812</td>\n",
              "      <td>20.135266</td>\n",
              "      <td>15.117692</td>\n",
              "      <td>12.740643</td>\n",
              "      <td>9.518290</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "      <td>5.606985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.013277</td>\n",
              "      <td>2.533600</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.076047</td>\n",
              "      <td>8.629439</td>\n",
              "      <td>11.788646</td>\n",
              "      <td>-36.313286</td>\n",
              "      <td>-12.760575</td>\n",
              "      <td>-30.383180</td>\n",
              "      <td>11.881278</td>\n",
              "      <td>-1.426010</td>\n",
              "      <td>3.807452</td>\n",
              "      <td>-10.524707</td>\n",
              "      <td>5.859927</td>\n",
              "      <td>-23.079763</td>\n",
              "      <td>-12.491269</td>\n",
              "      <td>2.837330</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>-12.231762</td>\n",
              "      <td>2.044090</td>\n",
              "      <td>0.890428</td>\n",
              "      <td>0.027614</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237062</td>\n",
              "      <td>1.938428e-02</td>\n",
              "      <td>2.050983</td>\n",
              "      <td>6.318859</td>\n",
              "      <td>4.887413</td>\n",
              "      <td>9.001948</td>\n",
              "      <td>28.238184</td>\n",
              "      <td>27.656061</td>\n",
              "      <td>12.539863</td>\n",
              "      <td>13.134631</td>\n",
              "      <td>23.081270</td>\n",
              "      <td>12.955017</td>\n",
              "      <td>9.619913</td>\n",
              "      <td>11.177006</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "      <td>7.884767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>11.921577</td>\n",
              "      <td>2.617082</td>\n",
              "      <td>0.422807</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.097656</td>\n",
              "      <td>7.745097</td>\n",
              "      <td>11.979889</td>\n",
              "      <td>-35.637835</td>\n",
              "      <td>-12.396089</td>\n",
              "      <td>-23.329157</td>\n",
              "      <td>-5.618912</td>\n",
              "      <td>-24.009019</td>\n",
              "      <td>-11.429958</td>\n",
              "      <td>-8.653911</td>\n",
              "      <td>-13.644327</td>\n",
              "      <td>-2.376830</td>\n",
              "      <td>-9.348086</td>\n",
              "      <td>-6.784202</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>3.796239</td>\n",
              "      <td>10.234004</td>\n",
              "      <td>2.068076</td>\n",
              "      <td>0.094723</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.795525</td>\n",
              "      <td>1.598664e+00</td>\n",
              "      <td>4.754235</td>\n",
              "      <td>7.618878</td>\n",
              "      <td>3.670433</td>\n",
              "      <td>13.263026</td>\n",
              "      <td>12.346275</td>\n",
              "      <td>9.793712</td>\n",
              "      <td>5.641880</td>\n",
              "      <td>7.715234</td>\n",
              "      <td>9.470948</td>\n",
              "      <td>6.940885</td>\n",
              "      <td>11.442204</td>\n",
              "      <td>13.338935</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "      <td>12.845447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>5.683850</td>\n",
              "      <td>3.031414</td>\n",
              "      <td>0.430326</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.108533</td>\n",
              "      <td>8.584561</td>\n",
              "      <td>12.893581</td>\n",
              "      <td>-29.518548</td>\n",
              "      <td>9.673216</td>\n",
              "      <td>-2.808057</td>\n",
              "      <td>-15.152383</td>\n",
              "      <td>4.970744</td>\n",
              "      <td>-11.303872</td>\n",
              "      <td>-40.637660</td>\n",
              "      <td>20.856397</td>\n",
              "      <td>-14.108397</td>\n",
              "      <td>11.416597</td>\n",
              "      <td>-0.283455</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>0.629552</td>\n",
              "      <td>1.342879</td>\n",
              "      <td>1.411308</td>\n",
              "      <td>0.031920</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.509826</td>\n",
              "      <td>1.164686e-01</td>\n",
              "      <td>3.236675</td>\n",
              "      <td>8.207434</td>\n",
              "      <td>13.450919</td>\n",
              "      <td>11.917909</td>\n",
              "      <td>7.435705</td>\n",
              "      <td>10.285392</td>\n",
              "      <td>15.423768</td>\n",
              "      <td>26.137803</td>\n",
              "      <td>19.249713</td>\n",
              "      <td>9.016201</td>\n",
              "      <td>7.068626</td>\n",
              "      <td>8.996079</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "      <td>3.526151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>5.503384</td>\n",
              "      <td>2.011310</td>\n",
              "      <td>0.436591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178825</td>\n",
              "      <td>8.422963</td>\n",
              "      <td>10.561135</td>\n",
              "      <td>-37.505530</td>\n",
              "      <td>-5.705017</td>\n",
              "      <td>-12.544108</td>\n",
              "      <td>-18.047612</td>\n",
              "      <td>-4.276282</td>\n",
              "      <td>0.332355</td>\n",
              "      <td>-11.281375</td>\n",
              "      <td>13.027097</td>\n",
              "      <td>-12.810990</td>\n",
              "      <td>-0.018912</td>\n",
              "      <td>-15.864451</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>-8.814279</td>\n",
              "      <td>1.074038</td>\n",
              "      <td>0.982837</td>\n",
              "      <td>0.044039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500858</td>\n",
              "      <td>5.623616e-01</td>\n",
              "      <td>2.217026</td>\n",
              "      <td>7.617375</td>\n",
              "      <td>20.022476</td>\n",
              "      <td>24.837219</td>\n",
              "      <td>15.282979</td>\n",
              "      <td>9.287309</td>\n",
              "      <td>6.227953</td>\n",
              "      <td>13.128940</td>\n",
              "      <td>17.797625</td>\n",
              "      <td>11.811849</td>\n",
              "      <td>18.531507</td>\n",
              "      <td>11.139822</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "      <td>14.294878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>2.848140</td>\n",
              "      <td>5.257087</td>\n",
              "      <td>0.429574</td>\n",
              "      <td>95.357857</td>\n",
              "      <td>-0.041301</td>\n",
              "      <td>8.643856</td>\n",
              "      <td>17.984012</td>\n",
              "      <td>-14.638249</td>\n",
              "      <td>33.258152</td>\n",
              "      <td>-1.678320</td>\n",
              "      <td>12.992081</td>\n",
              "      <td>-1.862723</td>\n",
              "      <td>-23.501156</td>\n",
              "      <td>-71.666480</td>\n",
              "      <td>46.931413</td>\n",
              "      <td>-10.265955</td>\n",
              "      <td>12.537933</td>\n",
              "      <td>-20.031008</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>-15.035719</td>\n",
              "      <td>1.019737</td>\n",
              "      <td>0.126359</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>3.508698</td>\n",
              "      <td>0.305190</td>\n",
              "      <td>1.776357e-15</td>\n",
              "      <td>0.294434</td>\n",
              "      <td>1.686673</td>\n",
              "      <td>3.427470</td>\n",
              "      <td>9.653605</td>\n",
              "      <td>10.097659</td>\n",
              "      <td>5.645688</td>\n",
              "      <td>7.278856</td>\n",
              "      <td>7.707348</td>\n",
              "      <td>7.020424</td>\n",
              "      <td>11.734898</td>\n",
              "      <td>10.182956</td>\n",
              "      <td>5.877306</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "      <td>8.576278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>6.049495</td>\n",
              "      <td>4.422018</td>\n",
              "      <td>0.397995</td>\n",
              "      <td>73.825417</td>\n",
              "      <td>-0.306061</td>\n",
              "      <td>8.592324</td>\n",
              "      <td>16.064863</td>\n",
              "      <td>-18.279023</td>\n",
              "      <td>23.902942</td>\n",
              "      <td>-2.479131</td>\n",
              "      <td>6.397297</td>\n",
              "      <td>-13.070048</td>\n",
              "      <td>-15.951344</td>\n",
              "      <td>-43.922407</td>\n",
              "      <td>33.254281</td>\n",
              "      <td>-10.803560</td>\n",
              "      <td>11.671482</td>\n",
              "      <td>-7.748786</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>4.369160</td>\n",
              "      <td>2.863041</td>\n",
              "      <td>0.642420</td>\n",
              "      <td>0.043014</td>\n",
              "      <td>36.972980</td>\n",
              "      <td>0.279739</td>\n",
              "      <td>1.545980e-01</td>\n",
              "      <td>1.488699</td>\n",
              "      <td>5.747723</td>\n",
              "      <td>16.293518</td>\n",
              "      <td>17.075112</td>\n",
              "      <td>7.749561</td>\n",
              "      <td>10.101882</td>\n",
              "      <td>15.055591</td>\n",
              "      <td>22.047078</td>\n",
              "      <td>21.258001</td>\n",
              "      <td>8.359991</td>\n",
              "      <td>14.422955</td>\n",
              "      <td>8.579866</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "      <td>6.880705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>355 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        kurt_m  logEnergy_m     zcr_m  ...     F2_std     F3_std     F4_std\n",
              "0     7.487398     3.254538  0.415539  ...   9.906564   9.906564   9.906564\n",
              "1     7.778342     2.756529  0.441604  ...  11.631959  11.631959  11.631959\n",
              "2     8.272703     2.009377  0.460902  ...   9.491288   9.491288   9.491288\n",
              "3    16.138859     5.341791  0.455639  ...   5.606985   5.606985   5.606985\n",
              "4     6.013277     2.533600  0.473684  ...   7.884767   7.884767   7.884767\n",
              "..         ...          ...       ...  ...        ...        ...        ...\n",
              "350  11.921577     2.617082  0.422807  ...  12.845447  12.845447  12.845447\n",
              "351   5.683850     3.031414  0.430326  ...   3.526151   3.526151   3.526151\n",
              "352   5.503384     2.011310  0.436591  ...  14.294878  14.294878  14.294878\n",
              "353   2.848140     5.257087  0.429574  ...   8.576278   8.576278   8.576278\n",
              "354   6.049495     4.422018  0.397995  ...   6.880705   6.880705   6.880705\n",
              "\n",
              "[355 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hv1cmZwAlU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "11ae357f-013e-4d4c-a4f0-4a0d42a2f7d7"
      },
      "source": [
        "y_train #Need to encode this "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      suspect\n",
              "1      suspect\n",
              "2      suspect\n",
              "3      suspect\n",
              "4      suspect\n",
              "        ...   \n",
              "350    healthy\n",
              "351    healthy\n",
              "352    healthy\n",
              "353    healthy\n",
              "354    healthy\n",
              "Name: label, Length: 355, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CRkuVinhtcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "c4d6feb2-1122-43fd-b736-8d3725691761"
      },
      "source": [
        "y_train = y_train.astype('category')\n",
        "y_train = y_train.cat.codes\n",
        "y_train.head(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    2\n",
              "2    2\n",
              "3    2\n",
              "4    2\n",
              "5    2\n",
              "6    2\n",
              "7    2\n",
              "8    2\n",
              "9    2\n",
              "dtype: int8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dIFbSpcSaT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "497f611d-bdee-42db-850f-063932b9b85d"
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.27.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 30.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrG9SF-_vHcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "09a98b64-0fcb-43b0-c248-8a178d687ba8"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import random\n",
        "random.seed(1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WveJQpC4Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split X_train and y_train for training a sequential model and prediction \n",
        "\n",
        "# split the dataset \n",
        "from sklearn.model_selection import train_test_split \n",
        "xx_train, xx_test, yy_train, yy_test = train_test_split(X_train, y_train, test_size=0.10, random_state = 127)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyxqeU0F501c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://towardsdatascience.com/getting-started-on-deep-learning-for-audio-data-667d9aa76a33"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUuqf28-5nuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Modification for Capturing sequence in audio data\n",
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "from keras import Sequential\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization,CuDNNLSTM, GRU, CuDNNGRU, Embedding, GlobalMaxPooling1D, GlobalAveragePooling1D, Flatten\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSEiC-umCc6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "321a6bf6-1be7-49b0-f239-875004059566"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization(momentum=0.98,input_shape=(418, 46)))\n",
        "model.add(Bidirectional(CuDNNGRU(128, return_sequences = True)))\n",
        "\n",
        "model.add(Dense(1,input_dim=46,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4J0m8297WKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "70774d3f-0c24-4d19-a599-1bbe61ec7335"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 418, 46)           184       \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 418, 256)          135168    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 418, 1)            257       \n",
            "=================================================================\n",
            "Total params: 135,609\n",
            "Trainable params: 135,517\n",
            "Non-trainable params: 92\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5OPslnyNdPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "de391ae5-6781-4f74-8a91-271e90907f91"
      },
      "source": [
        "xx_train = pad_sequences(xx_train, maxlen=10)\n",
        "xx_test = pad_sequences(xx_test, maxlen=10)\n",
        "yy_train = np.asarray(yy_train)\n",
        "yy_test = np.asarray(yy_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-492bb16f11a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0myy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0myy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'ogEnergy_m'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UUtJxjm51pC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "2b02a088-0cde-4b4b-b2eb-3d8aeadd81cc"
      },
      "source": [
        "#fit on a portion of the training data, and validate on the rest\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, min_lr=1e-8)\n",
        "early_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=20,  restore_best_weights=True)\n",
        "history = model.fit(xx_train, yy_train,batch_size=512, epochs=16,validation_data=[xx_test, yy_test],verbose = 2,callbacks=[reduce_lr,early_stop])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1c9495c26e26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected batch_normalization_1_input to have 3 dimensions, but got array with shape (418, 46)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 1.14.0. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoUDWptQ51fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPlMCXfjT1BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = yy_train.shape[0]\n",
        "filter_size = 2\n",
        "import keras\n",
        "\n",
        "def build_model_graph(input_shape=(465, 46)):\n",
        "    # define the keras model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=46, activation='relu',kernel_initializer=keras.initializers.glorot_uniform(seed=66)))\n",
        "    #model.add(Dense(8, activation='relu'))\n",
        "    #model.add(Bidirectional(CuDNNGRU(128,return_sequences = True)))\n",
        "    #model.add(Flatten())\n",
        "    model.add(BatchNormalization(momentum=0.98))\n",
        "    model.add(Dense(1, activation='sigmoid',kernel_initializer=keras.initializers.glorot_uniform(seed=66)))\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUEErf4swyDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "8c562f12-acd0-44bd-869f-457d6f0e4e49"
      },
      "source": [
        "model = build_model_graph()\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 12)                564       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12)                48        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 625\n",
            "Trainable params: 601\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrEBqNuEx8fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 100\n",
        "num_batch_size = 30\n",
        "history = model.fit(xx_train, yy_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(xx_test,yy_test), verbose=0,shuffle=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI2ZiGKiNOtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1aac8a40-219b-420a-fa29-e19e7c2bd552"
      },
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEICAYAAABCnX+uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDI12XVgNRA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "310e6cf7-ca04-4dc9-fe64-f2c60759f33e"
      },
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['acc'], label='train')\n",
        "plt.plot(history.history['val_acc'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXUTEJxToIiI+oUAXEfEJBbqIiE/8f7HW5kgUho8qAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImlMdmqJFHO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5728b4c0-b230-40da-8fdb-24deb9c35ac7"
      },
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(xx_train, yy_train, verbose=0)\n",
        "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
        "score = model.evaluate(xx_test, yy_test, verbose=0)\n",
        "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))\n",
        "\n",
        "\n",
        "#Training Accuracy: 95.97%\n",
        "#Testing Accuracy: 76.34%\n",
        "\n",
        "\n",
        "#Training Accuracy: 98.77%\n",
        "#Testing Accuracy: 72.14%\n",
        "\n",
        "\n",
        "#Training Accuracy: 92.58%\n",
        "#Testing Accuracy: 85.11%\n",
        "\n",
        "#Training Accuracy: 84.45%\n",
        "#Testing Accuracy: 82.98%\n",
        "\n",
        "#Training Accuracy: 82.54%\n",
        "#Testing Accuracy: 74.47%\n",
        "\n",
        "#Training Accuracy: 83.73%\n",
        "#Testing Accuracy: 80.85%\n",
        "\n",
        "\n",
        "#Training Accuracy: 84.45%\n",
        "#Testing Accuracy: 82.98%\n",
        "\n",
        "#Training Accuracy: 84.21%\n",
        "#Testing Accuracy: 82.98%\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 79.94%\n",
            "Testing Accuracy: 77.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ok2ABWQqDZ",
        "colab_type": "text"
      },
      "source": [
        "Fine tune the parameters to improve classification accuracy - if not then refine the features used - perhaps add weightage somewhere - aim for atleast 80% accuracy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjCCYSr7vqsq",
        "colab_type": "text"
      },
      "source": [
        "Generation 15 - Current best internal CV score: 0.7109589041095891\n",
        "\n",
        "Best pipeline: DecisionTreeClassifier(PolynomialFeatures(CombineDFs(input_matrix, input_matrix), degree=2, include_bias=False, interaction_only=False), criterion=entropy, max_depth=3, min_samples_leaf=18, min_samples_split=16)\n",
        "\n",
        "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
        "               disable_update_check=False, early_stop=None, generations=15,\n",
        "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
        "               mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
        "               periodic_checkpoint_folder=None, population_size=50,\n",
        "               random_state=42, scoring=None, subsample=1.0, template=None,\n",
        "               use_dask=False, verbosity=2, warm_start=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfocG7WYYBO",
        "colab_type": "text"
      },
      "source": [
        "Sequence Modeling \n",
        "\n",
        "\n",
        "hi, i just wanted to mention, about the modeling of features using sequence models. the current super basic way that I used is modeling chunks of X consecutive frames (so far I used 10frames) computing their mean and standard deviation.\n",
        "3:05\n",
        "You can use maybe this function as model. It is within the featureExtractionFunctions.py script\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_9RJd_3YiDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}