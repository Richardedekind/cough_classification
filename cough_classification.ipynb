{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Research references:\n",
    "#1) Dry/wet cough classification: https://link.springer.com/article/10.1007/s10439-013-0741-6\n",
    "#2) Pneumonia classification: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.io.wavfile import read\n",
    "#import wave\n",
    "import numpy as np\n",
    "import os\n",
    "import sox\n",
    "#import pywt #wavelets\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.utils import mediainfo\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features as spe_feats\n",
    "import pandas as pd\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.signal import lfilter\n",
    "import librosa\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply pre-emphasis (high-pass) filter\n",
    "def apply_preEmph(x):\n",
    "    x_filt = lfilter([1., -0.63], 1, x)\n",
    "    return x_filt\n",
    "        \n",
    "#Obtain autocorrelation\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[int((result.size+1)/2):] #Note: other people use re.size/2:, but this does not work for me \n",
    "                                   # TODO: check consistency in other computers\n",
    "#Get fundamental frequency (F0)\n",
    "def get_F0(x,fs):\n",
    "    #autocorrelation-based method to extract F0\n",
    "    xcorr_arr = autocorr(x)\n",
    "    \n",
    "    #looking for F0 in the frequency interval 50-500Hz, but we search in time domain\n",
    "    min_ms = round(fs/500)\n",
    "    max_ms = round(fs/50)\n",
    "    \n",
    "    xcorr_slot = xcorr_arr[max_ms+1:2*max_ms+1]\n",
    "    xcorr_slot = xcorr_slot[min_ms:max_ms]\n",
    "    t0 = np.argmax(xcorr_slot)\n",
    "    F0 = fs/(min_ms+t0-1)\n",
    "    return F0\n",
    "\n",
    "#Get formants\n",
    "def get_formants(x, lp_order):\n",
    "    #LP-based method\n",
    "    \n",
    "    #compute lp coefficients\n",
    "    a = librosa.lpc(x, lp_ord)\n",
    "\n",
    "    #get roots from lp coefficients\n",
    "    rts = np.roots(a)\n",
    "    rts = [r for r in rts if np.imag(r) >= 0]\n",
    "\n",
    "    #get angles\n",
    "    angz = np.arctan2(np.imag(rts), np.real(rts))\n",
    "\n",
    "    #get formant frequencies\n",
    "    formants = sorted(angz * (fs_targ / (2 * math.pi)))\n",
    "    \n",
    "    return formants\n",
    "\n",
    "#Extract frequencies\n",
    "def feature_extraction(x,fs,feats_df,lp_ord,ID):\n",
    "#Extract features from signal x (identified as ID), and concatenate them to dataframe feats_df\n",
    "#Features' reference: https://link.springer.com/article/10.1007/s10439-013-0741-6\n",
    "  \n",
    "    #TODO:\n",
    "    #0)Wavelets\n",
    "    \n",
    "    #DOUBT: if log-energy feature is included, should I also include the first mfcc coefficient (c0) ?\n",
    "    #1)mfcc\n",
    "    mfcc_feat = spe_feats.mfcc(x,fs)\n",
    "          \n",
    "    #2)zero-crossing rate\n",
    "    zcr_feat = (((x[:-1] * x[1:]) < 0).sum())/len(x)\n",
    "    \n",
    "    #3)Formant frequencies\n",
    "    #using LP-coeffcs-based method\n",
    "    form= get_formants(x, lp_ord)\n",
    "    \n",
    "    #we keep just the first 4 formants\n",
    "    formant_feats = form[0:4]\n",
    "    \n",
    "    #4)Log-energy\n",
    "    logEnergy_feat = np.log10( ( (np.power(x,2)).sum()/len(x) ) + eps)    \n",
    "    \n",
    "    #5)Pitch (F0)\n",
    "    F0_feat = get_F0(x,fs)\n",
    "    \n",
    "    #6)Kurtosis\n",
    "    kurt_feat = kurtosis(x)\n",
    "    \n",
    "    #7)Bispectrum Score (BGS)\n",
    "    #TODO\n",
    "    \n",
    "    #8)Non-Gaussianity Score (NGS)\n",
    "    #TODO\n",
    "    # Do kernel density estimation\n",
    "    #p = KernelDensity(kernel='gaussian', bandwidth=0.75).fit(seg_iarray)\n",
    "    #q generate Gaussian distribution? using mean and standard dev of reference data, plus min and max values?\n",
    "    \n",
    "    #9) Adding skewness as measure of non-gaussianity (not in paper)\n",
    "    skew_feat = skew(x)\n",
    "\n",
    "    feats_df = feats_df.append(pd.DataFrame({'Id': ID, 'mfcc': [mfcc_feat], \n",
    "                                       'kurtosis': kurt_feat, 'logEnergy': logEnergy_feat, 'zcr': zcr_feat,\n",
    "                                       'formants': [formant_feats], 'F0': F0_feat, 'skew': skew_feat},\n",
    "                                      index=[0]), ignore_index=True, sort=False)\n",
    "    return feats_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize data frame of features:\n",
    "\n",
    "feats = pd.DataFrame([])\n",
    "\n",
    "#tiny constant value\n",
    "eps = sys.float_info.epsilon\n",
    "\n",
    "#Features' settings:\n",
    "\n",
    "fs_targ = 16000 # set all audios to this sampling frequency\n",
    "n_channels_targ = 1\n",
    "\n",
    "#framing\n",
    "winlen=0.025\n",
    "winstep=0.01\n",
    "\n",
    "#mfcc\n",
    "mfcc_coeffcs= 12 #as paper (https://link.springer.com/article/10.1007/s10439-013-0741-6)\n",
    "\n",
    "lp_ord = int(round(2 + fs_targ/1000)) #standard rule of thumb for LP oder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "output_file: data/YT_set/wavs/norm/Dry Afternoon Cough-6LK6yHtIung_NORM.wav already exists and will be overwritten on build\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/YT_set/wavs/norm/Dry Afternoon Cough-6LK6yHtIung_NORM.wav\n",
      "High-pass filtering...\n",
      "Computing features...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "norm_skip = False #skip normalization step (because it has been done previously)\n",
    "\n",
    "#s = read(audiofile)\n",
    "FOLDER_PATH = 'data/YT_set/wavs/1/'\n",
    "for file_name in os.listdir(FOLDER_PATH):\n",
    "    \n",
    "    fname_noExt = os.path.splitext(file_name)[0] #file name without extension\n",
    "    \n",
    "    #full path file name\n",
    "    full_fname = FOLDER_PATH+file_name\n",
    "    #print(full_fname)\n",
    "    \n",
    "    #TODO: put normalized wavs in other folder\n",
    "    #name for normalization\n",
    "    NORM_FOLDER_PATH = 'data/YT_set/wavs/norm/'\n",
    "    norm_fname = NORM_FOLDER_PATH + os.path.splitext(file_name)[0] + '_NORM.wav'\n",
    "    \n",
    "    if norm_skip is False: \n",
    "        ## Normalization\n",
    "        \n",
    "        #level to same dB\n",
    "        tfm = sox.Transformer()\n",
    "        tfm.gain(gain_db=0.0, normalize=False, limiter=False, balance=None)\n",
    "        #downsample to 16kHz and 1 channel\n",
    "        tfm.convert(samplerate=fs_targ, n_channels=n_channels_targ, bitdepth=None) \n",
    "        #tfm.norm(db_level=0.0)\n",
    "    \n",
    "        # create the output normalized audio\n",
    "        \n",
    "        print(norm_fname)\n",
    "        tfm.build(full_fname, norm_fname)\n",
    "        tfm.effects_log\n",
    "    \n",
    "    # load normalized audio\n",
    "    s = AudioSegment.from_wav(norm_fname)\n",
    "    #sampling rate:\n",
    "    info = mediainfo(norm_fname)\n",
    "    fs = float(info['sample_rate'])\n",
    "    \n",
    "    #get ID of recording\n",
    "    ID = fname_noExt.split('-')[1] #for the current type of naming\n",
    "    \n",
    "    #get label\n",
    "    ## TODO: probably better to insert label in the file name, during creation of data set\n",
    "    \n",
    "    \n",
    "    ## Segmentation of cough streams (silence-based)\n",
    "    #min_silence_len in ms, silence_thresh in dB\n",
    "    s_segments = split_on_silence (s, min_silence_len = 600, silence_thresh = -30)\n",
    "    ## TODO: set more accurate thresholds, or find other way to split (variance-based?)\n",
    "    \n",
    "    #convert s_segments to numpy array format\n",
    "    AudioSegment2numpy_arr = lambda x: np.asarray(x.get_array_of_samples())\n",
    "    s_segments_np = list(map(AudioSegment2numpy_arr, s_segments))\n",
    "    \n",
    "    print('High-pass filtering...')\n",
    "    #pre-emphasis filtering to each segment\n",
    "    preEmph_filtering = lambda x: apply_preEmph(x)\n",
    "    s_segments_filt = list(map(preEmph_filtering, s_segments_np))\n",
    "    \n",
    "    #TODO\n",
    "    #2) the segment is divided into X non-overlapping subsegments (X=3 for dry/wet cough paper,\n",
    "    #X=12 for pneumonia paper)\n",
    "    #TODO: window framing: I think maybe the segments need to be windowed with non-overlapping frames? \n",
    "    #(see frame settings at beggining of notebook)\n",
    "    \n",
    "    print('Computing features...')\n",
    "    #Feature extraction for each segment\n",
    "    \n",
    "    #(lambda function doesn't work )\n",
    "    #feat_extr_step = lambda x, fs, feats_df, lp_ord, ID: feature_extraction(x,fs,feats_df,lp_ord,ID)\n",
    "    #feats = feat_extr_step(s_segments_filt,fs,feats,lp_ord,ID)\n",
    "    for idx, seg_i in enumerate(s_segments_filt):\n",
    "        print(idx)\n",
    "        feats = feature_extraction(seg_i,fs,feats,lp_ord,ID)\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Pre-proces the dataframe prior to use with a model (normalize if needed for the model, check there is no NaNs...)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cough sound\n",
    "#Breathing rate\n",
    "#Breathing rhytm (consistence smoothness)\n",
    "#Cough rate\n",
    "#Panic level\n",
    "#Hoarseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
